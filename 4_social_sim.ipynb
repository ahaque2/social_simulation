{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import time, enum, math\n",
    "import pylab as plt\n",
    "import random\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from state import State\n",
    "from Agent import MyAgent\n",
    "from NetworkInformationDiffusionModel import NetworkInformationDiffusionModel\n",
    "# from Visualization import Visualization\n",
    "from Data import Data\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_polarization(pol_incl):\n",
    "\n",
    "    mu = 0\n",
    "    pop1 = pol_incl[pol_incl > 0]\n",
    "    pop2 = pol_incl[pol_incl < 0]\n",
    "\n",
    "    if(pop1.shape[0] != 0 and pop2.shape[0] != 0):\n",
    "\n",
    "        dA = abs(len(pop1) - len(pop2))/pol_incl.shape[0]\n",
    "        d = abs(pop1.mean() - pop2.mean())/2\n",
    "        mu = (1-dA) * d\n",
    "\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def add_edges(G, data):\n",
    "    \n",
    "    visited = set()\n",
    "    add_edges = []\n",
    "    nodes = list(range(len(data)-3))\n",
    "    \n",
    "    q = deque([nodes.pop()])\n",
    "    \n",
    "    while len(nodes) > 0:\n",
    "        \n",
    "        if len(q) == 0:\n",
    "            q.append(nodes.pop())\n",
    "        cur = q.popleft()\n",
    "            \n",
    "        if cur not in visited:\n",
    "            cur_polInc = data.iloc[cur]['pol_inclination']\n",
    "            edges = list(G.edges(cur)).copy()\n",
    "            for edge in edges:\n",
    "                neighbor = edge[1]\n",
    "                if neighbor not in visited:\n",
    "                    q.append(neighbor)\n",
    "                    visited.add(neighbor)\n",
    "                    \n",
    "                    neighbors = list(G.edges(neighbor)).copy()\n",
    "                    # print(cur, neighbors, q)\n",
    "                    for n_edges in neighbors:\n",
    "                        n = n_edges[1]\n",
    "                        neigh_data = data.iloc[n]\n",
    "                        neigh_polInc = neigh_data['pol_inclination']\n",
    "                        tolerance = neigh_data['lat_rej'] - neigh_data['lat_acc']\n",
    "                        \n",
    "                        # print(cur, n, cur_polInc, neigh_polInc, tolerance)\n",
    "                        if abs(cur_polInc - neigh_polInc) < tolerance and cur != n:\n",
    "                            add_edges.append((cur, n))\n",
    "                        \n",
    "    G.add_edges_from(add_edges)\n",
    "    return G\n",
    "\n",
    "\n",
    "def sever_edges(G, data):\n",
    "    \n",
    "    visited = set()\n",
    "    remove_edges = []\n",
    "    nodes = list(range(len(data)-3))\n",
    "    \n",
    "    q = deque([nodes.pop()])\n",
    "    \n",
    "    while len(nodes) > 0:\n",
    "        \n",
    "        if len(q) == 0:\n",
    "            q.append(nodes.pop())\n",
    "        cur = q.popleft()\n",
    "        \n",
    "        if cur not in visited:\n",
    "            cur_polInc = data.iloc[cur]['pol_inclination']\n",
    "            edges = list(G.edges(cur)).copy()\n",
    "            for edge in edges:\n",
    "                neighbor = edge[1]\n",
    "                if neighbor not in visited:\n",
    "                    q.append(neighbor)\n",
    "                    visited.add(neighbor)\n",
    "                    neigh_data = data.iloc[neighbor]\n",
    "                    neigh_polInc = neigh_data['pol_inclination']\n",
    "                    tolerance = neigh_data['lat_rej'] - neigh_data['lat_acc']\n",
    "                    if abs(cur_polInc - neigh_polInc) > tolerance:\n",
    "                        remove_edges.append((cur, neighbor))\n",
    "                        \n",
    "    G.remove_edges_from(remove_edges)\n",
    "    return G\n",
    "\n",
    "def aggregate_sanction_graph(graphs):\n",
    "    edge_weights = defaultdict(list)\n",
    "\n",
    "    for G in graphs:\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            weight = data.get('weight', 1.0)\n",
    "            edge_weights[(u, v)].append(weight)\n",
    "\n",
    "    aggregated = nx.DiGraph()\n",
    "    for (u, v), weights in edge_weights.items():\n",
    "        mean_weight = sum(weights) / len(weights)\n",
    "        aggregated.add_edge(u, v, weight=mean_weight)\n",
    "\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "def plot(G):\n",
    "\n",
    "    indegrees = [G.degree(n) * 10 for n in G.nodes()]  # Scale for visibility\n",
    "    pos = nx.spring_layout(G)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    nx.draw(G, with_labels=True, edge_color=\"gray\", node_size=indegrees)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def update_news_followers(G, data, SancGraphs):\n",
    "    \n",
    "    aggSanc = aggregate_sanction_graph(SancGraphs)\n",
    "    \n",
    "    remove_edges = []\n",
    "    add_edges = []\n",
    "    \n",
    "    for n in [100, 101, 102]:\n",
    "        followers_sanct = []\n",
    "        \n",
    "        if n in aggSanc:\n",
    "            for u, v, w in aggSanc.in_edges(n, data=True):\n",
    "                weight = w.get('weight')\n",
    "                followers_sanct.append((u, weight))\n",
    "            followers_df = pd.DataFrame(followers_sanct, columns = ['followers', 'sanctions'])\n",
    "            # print(followers_df)\n",
    "            \n",
    "            # sys.exit()\n",
    "\n",
    "            negative_df = followers_df[followers_df['sanctions'] < 0].copy()\n",
    "            negative_df['abs_sanctions'] = negative_df['sanctions'].abs()\n",
    "            total_weight = negative_df['abs_sanctions'].sum()\n",
    "            negative_df['prob'] = negative_df['abs_sanctions'] / total_weight\n",
    "\n",
    "            # Step 4: Determine number to pick (10%, ceil)\n",
    "            # num_to_pick = math.ceil(len(negative_df) * 0.1)\n",
    "            num_to_pick = min(3, math.ceil(len(negative_df) * 0.1))\n",
    "\n",
    "            # Step 5: Sample followers\n",
    "            if negative_df['prob'].sum() > 0:\n",
    "                selected = negative_df.sample(n=num_to_pick, weights='prob', replace=False)\n",
    "            else:\n",
    "                selected = negative_df.sample(n=num_to_pick, replace=False)\n",
    "                \n",
    "\n",
    "            for follower in selected['followers']:\n",
    "                remove_edges.append((n, follower))\n",
    "                \n",
    "            nonfollowers = [i for i in range(100) if i not in followers_df.followers.tolist()]\n",
    "            nonfollowers_df = data.iloc[nonfollowers]\n",
    "            \n",
    "            news_pol = data.iloc[n]['pol_inclination']\n",
    "            nonfollowers_df['diff'] = (nonfollowers_df['pol_inclination'] - news_pol).abs()\n",
    "            \n",
    "            # print(followers_df)\n",
    "            # print('------------------')\n",
    "            # print(nonfollowers_df)\n",
    "            \n",
    "            num_to_pick = min(3, math.ceil(len(nonfollowers_df) * 0.1))\n",
    "\n",
    "            # Sample using 'score' as weights\n",
    "            diff = 1/(nonfollowers_df['diff'] + 1e-6)\n",
    "            \n",
    "            sampled_df = nonfollowers_df.sample(n=num_to_pick, weights=diff, replace=False)\n",
    "            \n",
    "            # print('------------------')\n",
    "            # print(sampled_df)\n",
    "            \n",
    "            for nonfol in sampled_df.index.tolist():\n",
    "                add_edges.append((n, nonfol))\n",
    "            \n",
    "            # sys.exit()\n",
    "            \n",
    "\n",
    "    # print(\"Here\")\n",
    "    # print(remove_edges)\n",
    "    # print(add_edges)\n",
    "    \n",
    "    G.remove_edges_from(remove_edges)\n",
    "    G.add_edges_from(add_edges)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trending_topics = {1:[-1, -1.2], 2:[2, 0], 3:[-2, 0.3], 4:[0, 12], 5:[8, 10], 6:[0, 3]}\n",
    "\n",
    "def normalize(i, weighted_dict):\n",
    "    \n",
    "    # wd = weighted_dict.deepcopy()\n",
    "    \n",
    "    wd = {k: v[:] for k, v in weighted_dict.items()}\n",
    "\n",
    "    vals = [v[i] for v in wd.values()]\n",
    "    min_v, max_v = min(vals), max(vals)\n",
    "    rng = max_v - min_v or 1\n",
    "    for v in wd.values(): v[i] = (v[i] - min_v) / rng\n",
    "    \n",
    "    return wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pick_an_author(news_stats): \n",
    "    \n",
    "    if all(all(v == 1 for v in values) for values in news_stats.values()) or all(all(v == 0 for v in values) for values in news_stats.values()):\n",
    "        return random.choices([100, 101, 102])[0]\n",
    "    \n",
    "    news_stats = normalize(0, news_stats)\n",
    "    news_stats = normalize(1, news_stats)\n",
    "    \n",
    "    keys, weights = zip(*[(k, sum(v) / len(v)) for k, v in news_stats.items()])\n",
    "    author_id = random.choices(keys, weights=weights)[0]\n",
    "    \n",
    "    return author_id\n",
    "\n",
    "def pick_a_topic(trending_topics, author_id, topic_choices, news_topic_pref, post_conf):\n",
    "    \n",
    "    if post_conf.shape[0] == 0:\n",
    "        print(\"No More posts to choose from!\")\n",
    "        return None\n",
    "        # sys.exit()\n",
    "        \n",
    "    if len(topic_choices) == 1:\n",
    "        return topic_choices[0], trending_topics, topic_choices, news_topic_pref\n",
    "        \n",
    "    if all(all(v == 1 for v in values) for values in trending_topics.values()) or all(all(v == 0 for v in values) for values in trending_topics.values()):\n",
    "        # print()\n",
    "        w = [news_topic_pref[author_id][i-1] for i in topic_choices]\n",
    "        # print(\"weights \", w)\n",
    "        return random.choices(topic_choices, weights = w)[0], trending_topics, topic_choices, news_topic_pref\n",
    "    \n",
    "    trending_topics = normalize(0, trending_topics)\n",
    "    trending_topics = normalize(1, trending_topics)\n",
    "    \n",
    "    keys, weights = zip(*[(k, sum(v) / len(v)) for k, v in trending_topics.items()])\n",
    "    topic_weights = [news_topic_pref[author_id][i-1] for i in topic_choices]\n",
    "    weights = [w*n for w, n in zip(weights, topic_weights)]\n",
    "    try:\n",
    "        topic_id = random.choices(keys, weights=weights)[0]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"weights \", weights)\n",
    "        sys.exit()\n",
    "    \n",
    "    # print(\"topic\", topic_id, \"\\t\", post_conf[post_conf['topic'] == topic_id].shape, \"\\t\")\n",
    "    \n",
    "    # sampled_post = post_conf[post_conf.topic == picked_topic].sample()\n",
    "    \n",
    "    if post_conf[post_conf['topic'] == topic_id].shape[0] == 0:\n",
    "        \n",
    "        topic_choices.remove(topic_id)\n",
    "        \n",
    "        del trending_topics[topic_id]\n",
    "        \n",
    "        # print(\"Here\")\n",
    "        # print(\"Here topic\", topic_id, \"\\t\", post_conf[post_conf['topic'] == topic_id].shape, \"\\t\", trending_topics, topic_choices)\n",
    "        # time.sleep(5)\n",
    "        topic_id, trending_topics, topic_choices, news_topic_pref = pick_a_topic(trending_topics, author_id, topic_choices, news_topic_pref, post_conf)\n",
    "        \n",
    "    return topic_id, trending_topics, topic_choices, news_topic_pref\n",
    "\n",
    "\n",
    "def sample_post(post_conf, picked_topic, author_id, data):\n",
    "    \n",
    "    stance = data.iloc[author_id][f'topic_{picked_topic}']\n",
    "    \n",
    "    # print(\"stance \",  stance)\n",
    "    post_conf = post_conf[post_conf.topic == picked_topic]\n",
    "    post_conf['diff'] = (post_conf['stance'] - stance).abs()\n",
    "    \n",
    "    # print(\"here \", picked_topic)\n",
    "    # print(post_conf)\n",
    "    \n",
    "    probs = 1 / (post_conf['diff'] + 1e-6)\n",
    "    row = post_conf.sample(weights=probs)\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_data(df, data, attr):\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if(df.iloc[i][attr] != data.iloc[i][attr]):\n",
    "            print(\"old value \", df.iloc[i][attr], \" \\t New value\", data.iloc[i][attr])\n",
    "\n",
    "def update_user_attributes(data, G, user, agg_sanct, attr):\n",
    "    \n",
    "    old_attribute = data.copy().iloc[user][attr]\n",
    "    \n",
    "    update_val = agg_sanct * 0.1\n",
    "    \n",
    "    update_val = max(-0.05, min(update_val, 0.05))\n",
    "    \n",
    "    ## NEED TO CHANGE THIS FORMULA TO BE SOMETHING MORE MEANINGFUL\n",
    "    new_attribute = old_attribute + update_val\n",
    "    \n",
    "    #Update the user activity with the new value (a bounded value between 0 and 1)\n",
    "    new_attribute = max(min(1, new_attribute), 0)\n",
    "    #data.at[user, 'privacy'] = new_attribute\n",
    "    \n",
    "    if attr == 'privacy':\n",
    "        if user in user_sanc_pr:\n",
    "            user_sanc_pr[user].append(agg_sanct)\n",
    "        else:\n",
    "            user_sanc_pr[user] = [agg_sanct]\n",
    "    \n",
    "    if attr == 'activity':\n",
    "        if user in user_sanc_act:\n",
    "            user_sanc_act[user].append(agg_sanct)\n",
    "        else:\n",
    "            user_sanc_act[user] = [agg_sanct]\n",
    "    \n",
    "    # if(old_attribute == new_attribute and agg_sanct > 1e-14 and old_attribute != 1):\n",
    "    #     print(old_attribute)\n",
    "    #     print(agg_sanct)\n",
    "    #     sys.exit()\n",
    "    \n",
    "    # print(\"before \", data.iloc[user])\n",
    "    \n",
    "    data[attr].iloc[user] = new_attribute\n",
    "    G.nodes[user][attr] = new_attribute\n",
    "    \n",
    "    # print(\"Update user attribute :\", attr, old_attribute, new_attribute, user)\n",
    "    \n",
    "    # print(\"After \", data.iloc[user])\n",
    "    \n",
    "    return data, G\n",
    "    \n",
    "# def attitude_shift(sanction_score, att_diff, author_inclination, reciever_inclination):\n",
    "    \n",
    "#     attitude_shft = 0.1 * sanction_score * 1/(att_diff+1)\n",
    "#     if(author_inclination >= reciever_inclination):\n",
    "#         new_user_incl = author_inclination - attitude_shft\n",
    "#     else:\n",
    "#         new_user_incl = author_inclination + attitude_shft\n",
    "        \n",
    "#     return new_user_incl\n",
    "\n",
    "\n",
    "def update_satisfaction(data, G, user, agg_sanct):\n",
    "    \n",
    "    old_satisfaction = data.copy().iloc[user]['satisfaction']\n",
    "    \n",
    "    # old_satisfaction = user_data['satisfaction']\n",
    "    \n",
    "    ## NEED TO CHANGE THIS FORMULA TO BE SOMETHING MORE MEANINGFUL\n",
    "    new_satisfaction = old_satisfaction + (agg_sanct * 0.1)\n",
    "    \n",
    "    # print(\"before \", data.iloc[user])\n",
    "    \n",
    "    if user in user_sanc_sat:\n",
    "        user_sanc_sat[user].append(agg_sanct)\n",
    "    else:\n",
    "        user_sanc_sat[user] = [agg_sanct]\n",
    "    \n",
    "    data['satisfaction'].iloc[user] = new_satisfaction\n",
    "    G.nodes[user]['satisfaction'] = new_satisfaction\n",
    "    \n",
    "    # print(\"Update in satisfaction :\", old_satisfaction, new_satisfaction, user)\n",
    "    # sys.exit()\n",
    "    \n",
    "    # print(\"After \", data.iloc[user])\n",
    "    # sys.exit()\n",
    "    \n",
    "    return data, G\n",
    "\n",
    "def clamp(num, minn, maxx):\n",
    "    return minn if num < minn else maxx if num > maxx else num\n",
    "\n",
    "\n",
    "# def update_activity(data, G, state, post, lower_attd_th, upper_attd_th):\n",
    "    \n",
    "#     old_activity = data.copy()\n",
    "#     # old_activity['shift'] = [0] * old_activity.shape[0]\n",
    "#     topic_id = post['topic']\n",
    "    \n",
    "#     # user_stance = data[f'topic_{topic_id}'].copy()\n",
    "#     # old_activity[(abs(user_stance - post['stance']) < lower_attd_th)]\n",
    "#     # print(old_activity[f'topic_{topic_id}'].shape)\n",
    "    \n",
    "#     old_activity['shift'] = np.select([abs(old_activity[f'topic_{topic_id}'] - post['stance']) < lower_attd_th, abs(old_activity[f'topic_{topic_id}'] - post['stance']) > upper_attd_th], [1, -1], default=0)\n",
    "    \n",
    "#     # print(old_activity['shift'].value_counts())\n",
    "    \n",
    "#     state_df = pd.Series(state)\n",
    "#     state_df = state_df.map(lambda x: 1 if x != 2 else 0)\n",
    "    \n",
    "#     # print(state_df.value_counts())\n",
    "    \n",
    "#     old_activity['activity'] = old_activity['activity'] + old_activity['activity'] * old_activity['shift'] * state_df * post['stance'] * 0.1\n",
    "#     old_activity['activity'] = old_activity['activity'].clip(lower=0, upper=1)\n",
    "#     # print(new_activity.describe())\n",
    "#     # sys.exit()\n",
    "\n",
    "#     return old_activity\n",
    "\n",
    "def update_user_preferences(sG, G, data, state, post, lower_attd_th, upper_attd_th):\n",
    "    \n",
    "    topic_id = post['topic']\n",
    "    labels = nx.get_edge_attributes(sG,'weight')\n",
    "    outgoing = list(set([x[0] for x in labels.keys()]) - set([100, 101, 102]))\n",
    "    incoming = list(set([x[1] for x in labels.keys()]) - set([100, 101, 102]))\n",
    "    updated_data = data\n",
    "    \n",
    "    # print('labels ', labels)\n",
    "    \n",
    "    # print('outgoing ', outgoing)\n",
    "    \n",
    "    # print('incoming ', incoming)\n",
    "    \n",
    "    # print('post ', post)\n",
    "    \n",
    "#     sys.exit()\n",
    "    \n",
    "    # print(updated_data.shape)\n",
    "    # print(updated_data)\n",
    "    # sys.exit()\n",
    "    \n",
    "    for n in incoming:\n",
    "        lab = [labels[x] for x in labels if x[1] == n]\n",
    "        agg_sanct = sum(lab)/len(lab)\n",
    "        \n",
    "        # print(n, agg_sanct)\n",
    "        # sys.exit()\n",
    "        \n",
    "        updated_data, G = update_user_attributes(updated_data, G, n, agg_sanct, 'privacy')\n",
    "        updated_data, G = update_satisfaction(updated_data, G, n, agg_sanct)\n",
    "        \n",
    "    # print(\"Updated Data\", updated_data)\n",
    "    # sys.exit()\n",
    "        \n",
    "    for n in outgoing:\n",
    "        lab = [labels[x] for x in labels if x[0] == n]\n",
    "        agg_sanct = sum(lab)/len(lab)\n",
    "        \n",
    "        # print(n, agg_sanct)\n",
    "        # sys.exit()\n",
    "        \n",
    "        updated_data, G = update_user_attributes(updated_data, G, n, agg_sanct, 'activity')\n",
    "        # updated_data, G = update_satisfaction(updated_data, G, n, agg_sanct)\n",
    "    \n",
    "    # updated_data = update_activity(updated_data, G, state, post, lower_attd_th, upper_attd_th)\n",
    "    \n",
    "    for node in incoming:\n",
    "        \n",
    "        edges = sG.in_edges(node, data=True)\n",
    "        gama = 0\n",
    "        temp_df = pd.DataFrame(columns = ['author', 'author_pol', 'reciever', 'reciever_pol', 'att_diff', 'sanction_scores', 'lat_acc', 'lat_rej', 'att_shift'])\n",
    "        \n",
    "        # if(len(edges) > 1):\n",
    "        #     print(edges)\n",
    "        #     print(\"HEEEEERRRRREEEEEEEEE\")\n",
    "        #     sys.exit()\n",
    "        \n",
    "        att_change = 0\n",
    "        for x in edges:\n",
    "            reciever = x[0]\n",
    "            author = x[1]\n",
    "            sanction_score = x[2]['weight']\n",
    "            \n",
    "            lat_acc = updated_data[updated_data['id'] == author]['lat_acc'].values[0]\n",
    "            lat_rej = updated_data[updated_data['id'] == author]['lat_rej'].values[0]\n",
    "\n",
    "            reciever_inclination = updated_data[updated_data['id'] == reciever]['pol_inclination'].values[0]\n",
    "            author_inclination = updated_data[updated_data['id'] == author]['pol_inclination'].values[0]\n",
    "            att_diff =  abs(reciever_inclination - author_inclination)\n",
    "            \n",
    "            att_shift = 0\n",
    "            \n",
    "            if att_diff <= lat_acc:\n",
    "                att_shift = (sanction_score * 0.1)/(1+att_diff)\n",
    "                \n",
    "            elif att_diff >= lat_rej:\n",
    "                att_shift = -1 * (sanction_score * 0.1)/(1+att_diff)\n",
    "                \n",
    "            temp_dict = {'author':author, 'author_pol':author_inclination, 'reciever':reciever, 'reciever_pol':reciever_inclination, 'att_diff':att_diff, \n",
    "                         'sanction_scores':sanction_score, 'lat_acc': lat_acc, 'lat_rej': lat_rej, 'att_shift': att_shift}\n",
    "            temp_df = temp_df.append(temp_dict, ignore_index=True)\n",
    "            \n",
    "            att_change += att_shift\n",
    "            \n",
    "            # new_stance = G.nodes[author]['topic_' + str(topic_id)] + att_shift\n",
    "            \n",
    "            # updated_data['topic_' + str(topic_id)].iloc[author] = new_stance\n",
    "            # G.nodes[author]['topic_' + str(topic_id)] = new_stance\n",
    "            \n",
    "        # temp_df['adj_att_diff'] = temp_df['att_diff'] + 1\n",
    "        \n",
    "        # temp_df['att_shift'] = temp_df['sanction_scores'] * 0.1/temp_df['adj_att_diff']\n",
    "        \n",
    "        att_change = max(-0.05, min(att_change, 0.05))\n",
    "        \n",
    "        new_stance = updated_data['topic_' + str(topic_id)].iloc[author] + att_change\n",
    "        new_stance = np.clip(new_stance, -1, 1)\n",
    "        \n",
    "        updated_data['topic_' + str(topic_id)].iloc[author] = new_stance\n",
    "        G.nodes[author]['topic_' + str(topic_id)] = new_stance\n",
    "        \n",
    "    return updated_data, G\n",
    "\n",
    "def update_pol_pol_in_graph(data, G):\n",
    "    \n",
    "    for n in G:\n",
    "        G.nodes[n]['pol_inclination'] = data.iloc[n]['pol_inclination']\n",
    "        \n",
    "    return G\n",
    "\n",
    "def run_simulation(post, G, steps, seed):\n",
    "\n",
    "    model = NetworkInformationDiffusionModel(post, G, se_flag, se_threshold, topic_weights, seed)\n",
    "    for i in range(steps):\n",
    "\n",
    "        model.reset_randomizer(seed)\n",
    "        model.step(i)\n",
    "        #agent_state = model.datacollector.get_agent_vars_dataframe()\n",
    "        #X = pd.pivot_table(agent_state.reset_index(), index='Step', columns='State', aggfunc=np.size, fill_value=0)  \n",
    "        \n",
    "    #print(model.datacollector.get_agent_vars_dataframe())\n",
    "    agent_state = model.datacollector.get_agent_vars_dataframe()\n",
    "    \n",
    "    states = [int(i.state) for i in model.grid.get_all_cell_contents()]\n",
    "    agents = model.agents\n",
    "    \n",
    "    return model, states, agents, model.G, model.G_share, agent_state\n",
    "\n",
    "def start_simulation(c_i, c_k, data, G, post_conf, n_topics, lower_attd_th, upper_attd_th, seed, trending_topics, topic_choices, news_topic_pref):\n",
    "    \n",
    "    steps=10\n",
    "    SimModel, states, agents, AgentGraphs, runtime = {}, [], [], [], []\n",
    "    network_homophily = []\n",
    "    net_homophily = []\n",
    "    polarization, polarization2 = [], []\n",
    "    satisfaction = []\n",
    "    activity = []\n",
    "    users_activities = []\n",
    "    privacy = []\n",
    "    polarity = []\n",
    "    avg_polarity = []\n",
    "    agent_pol_inclination = []\n",
    "    SancGraphs = []\n",
    "    i = 0\n",
    "    sharing_details = []\n",
    "    updated_data = pd.DataFrame()\n",
    "    G_agents = None\n",
    "    # print(c_k, \"\\t\", c_i, \"\\t\")\n",
    "    \n",
    "    # for j, post in post_conf.iterrows():\n",
    "    while post_conf.shape[0] > 0:\n",
    "\n",
    "        i+=1\n",
    "        \n",
    "        st=time.time()\n",
    "        # author_id = pick_an_author(data, pc)\n",
    "        author_id = pick_an_author(news_stats)\n",
    "        # print(news_stats, \"\\t\", author_id, \"\\n\\n\")\n",
    "        \n",
    "        # print(\"author_id\", author_id)\n",
    "        \n",
    "        # print(\"topic_choices \", topic_choices)\n",
    "        # print(\"trending_topics \", trending_topics)\n",
    "        \n",
    "        # print(\"Here \", pick_a_topic(trending_topics, author_id, topic_choices, post_conf))\n",
    "        \n",
    "        # sys.exit(0)\n",
    "        \n",
    "        picked_topic, trending_topics, topic_choices, news_topic_pref = pick_a_topic(trending_topics, author_id, topic_choices, news_topic_pref, post_conf)\n",
    "        \n",
    "        if not picked_topic and post_conf[post_conf.topic == picked_topic].shape[0] == 0:\n",
    "            print(\"no more posts for \", picked_topic, post_conf[post_conf.topic == picked_topic].shape)\n",
    "            sys.exit(0)\n",
    "        \n",
    "        # print(\"picked_topic\", picked_topic)\n",
    "        \n",
    "        # print(i, picked_topic, post_conf.shape, post_conf[post_conf.topic == picked_topic].shape, '\\n')\n",
    "        print(i, post_conf.shape, end = '\\r')\n",
    "        \n",
    "        sampled_post = sample_post(post_conf, picked_topic, author_id, data)\n",
    "        # post_conf[post_conf.topic == picked_topic].sample()\n",
    "        post_conf.drop(sampled_post.index, inplace = True)\n",
    "        # post_conf = \n",
    "        \n",
    "        #author_id = int(post['author_id'])\n",
    "        \n",
    "#         if(author_id == None):\n",
    "#             continue\n",
    "\n",
    "        post = dict()\n",
    "        post['author'] = author_id\n",
    "        post['topic'] = sampled_post.topic.values[0]\n",
    "        post['stance'] = sampled_post.stance.values[0]\n",
    "        \n",
    "        # print(post)\n",
    "        # sys.exit()\n",
    "\n",
    "        SimModel[i], state, agent, G_agents, G_sanctions, agent_state = run_simulation(post, G, steps, seed)\n",
    "        \n",
    "        # return G_sanctions\n",
    "        \n",
    "        # print(len(state))\n",
    "        # print(agent_state)\n",
    "        # sys.exit(0)\n",
    "        \n",
    "        # et = time.time()\n",
    "        # rt = round(et-st, 6)\n",
    "\n",
    "        states.append(state) \n",
    "        agents.append(agent)\n",
    "        AgentGraphs.append(G_agents)\n",
    "        SancGraphs.append(G_sanctions)\n",
    "        # AgentStates.append(agent_state)\n",
    "        # runtime.append(rt)\n",
    "\n",
    "        author = author_id\n",
    "        #received_agents_count = sum([1 for x in state if x == 1])\n",
    "        not_received_agents_count = sum([1 for x in state if x == 2])\n",
    "        spreader_agents_count = sum([1 for x in state if x == 3])\n",
    "        disinterested_agents_counts = sum([1 for x in state if x == 4])\n",
    "        received_agents_count = spreader_agents_count + disinterested_agents_counts\n",
    "        \n",
    "        content_reach = received_agents_count * 0.01\n",
    "        sanc = list(nx.get_edge_attributes(G_sanctions, 'weight').values())\n",
    "        sanc = [abs(s) for s in sanc]\n",
    "        agg_sanctions = sum(sanc) / len(sanc) if sanc else 0\n",
    "        \n",
    "        alpha = 0.9\n",
    "        beta = 0.1\n",
    "        news_stats[author_id][0] = alpha * news_stats[author_id][0] + beta * content_reach\n",
    "        news_stats[author_id][1] = alpha * news_stats[author_id][1] + beta * agg_sanctions\n",
    "        \n",
    "        trending_topics[post['topic']][0] = beta * trending_topics[post['topic']][0] + alpha * content_reach\n",
    "        \n",
    "        if post['stance'] * data.iloc[author_id][post['topic']] >= 0:\n",
    "            trending_topics[post['topic']][1] = beta * trending_topics[post['topic']][1] + alpha * agg_sanctions\n",
    "        else:\n",
    "            trending_topics[post['topic']][1] = beta * trending_topics[post['topic']][1] - alpha * agg_sanctions\n",
    "\n",
    "        #print(state)\n",
    "        sharing_details.append([post['topic'], round(post['stance'], 6), author_id, received_agents_count, not_received_agents_count, spreader_agents_count, disinterested_agents_counts])\n",
    "        #print(sharing_details)\n",
    "\n",
    "        # Visualization().plot_sim_network(G_agents, state)\n",
    "        # Visualization().plot_sanction_graph(G_sanctions)\n",
    "        # sys.exit()\n",
    "        \n",
    "        # Update user preferences based on sanctions received from other agents\n",
    "        data_updated, G_agents = update_user_preferences(G_sanctions, G_agents, data.copy(), state, post, lower_attd_th, upper_attd_th)\n",
    "        \n",
    "        updated_data = data_updated.copy()\n",
    "        \n",
    "        # print(\"Comparison \", data['activity'].compare(updated_data['activity']))\n",
    "        data = data_updated\n",
    "        \n",
    "#         print(updated_data.shape, updated_data.columns)\n",
    "#         print(n_topics)\n",
    "        \n",
    "#         topics = ['topic_' + str(x) for x in range(n_topics)]\n",
    "        \n",
    "#         kx = updated_data[topics].mean(axis = 1)\n",
    "#         temp_df = updated_data[topics]\n",
    "#         print(temp_df.shape, temp_df.columns)\n",
    "#         print(temp_df.head())\n",
    "#         print(kx)\n",
    "        \n",
    "#         sys.exit()\n",
    "        \n",
    "        # pol_inclination = Data_obj.get_agent_pol_inclinations(updated_data, n_topics)\n",
    "        # pol_inclination = get_agent_pol_inclinations(updated_data)\n",
    "        # updated_data['pol_inclination'] = (updated_data[['topic_1', 'topic_2', 'topic_3']].mean(axis=1) - updated_data[['topic_4', 'topic_5', 'topic_6']].mean(axis=1))/2\n",
    "        updated_data['pol_inclination'] = ((updated_data[['topic_1', 'topic_2', 'topic_3']] * -1).sum(axis = 1) + (updated_data[['topic_4', 'topic_5', 'topic_6']]).sum(axis = 1))/6\n",
    "        pol_inclination = updated_data['pol_inclination']\n",
    "        \n",
    "        if(updated_data['pol_inclination'].isna().sum() > 0):\n",
    "            #print(pol_inclination)\n",
    "            \n",
    "            print(\"updated_data \", updated_data)\n",
    "            sys.exit()\n",
    "            \n",
    "        # updated_data['pol_inclination'] = pol_inclination\n",
    "        \n",
    "        agent_pol_inclination.append(pol_inclination)\n",
    "        \n",
    "        G_agents = update_pol_pol_in_graph(updated_data, G_agents)\n",
    "        \n",
    "        net_satisfaction = updated_data['satisfaction'].mean()\n",
    "        satisfaction.append(net_satisfaction)\n",
    "        \n",
    "        mean_activity = updated_data['activity'].mean()\n",
    "        users_activities.append(updated_data['activity'])\n",
    "        activity.append(mean_activity)\n",
    "        \n",
    "        mean_privacy = updated_data['privacy'].mean()\n",
    "        users_activities.append(updated_data['privacy'])\n",
    "        privacy.append(mean_privacy)\n",
    "        \n",
    "        pol = round(math.sqrt(sum([x*x for x in updated_data['pol_inclination']])/updated_data.shape[0]), 6)\n",
    "        \n",
    "        if(math.isnan(pol)):\n",
    "            \n",
    "            print(updated_data['pol_inclination'])\n",
    "            sys.exit()\n",
    "        \n",
    "        avg_pol = round(updated_data['pol_inclination'].mean(), 6)\n",
    "        \n",
    "        temp_G = G.copy()\n",
    "        \n",
    "        node_attr = updated_data.set_index('id').to_dict('index')\n",
    "        # print(node_attr)\n",
    "        # print((data['activity'] - updated_data['activity']).sum())\n",
    "        \n",
    "        # sys.exit()\n",
    "        nx.set_node_attributes(temp_G, node_attr)\n",
    "         \n",
    "        for n in temp_G.nodes:\n",
    "            if(node_attr[n]['pol_inclination'] < -0.6):\n",
    "                node_attr[n]['pol_inclination_grp'] = -2\n",
    "            elif((node_attr[n]['pol_inclination'] >= -0.6) and ((node_attr[n]['pol_inclination'] < -0.2))):\n",
    "                node_attr[n]['pol_inclination_grp'] = -1\n",
    "            elif((node_attr[n]['pol_inclination'] >= -0.2) and ((node_attr[n]['pol_inclination'] <= 0.2))):\n",
    "                node_attr[n]['pol_inclination_grp'] = 0\n",
    "            elif((node_attr[n]['pol_inclination'] > 0.2) and ((node_attr[n]['pol_inclination'] <= 0.6))):\n",
    "                node_attr[n]['pol_inclination_grp'] = 1\n",
    "            elif(node_attr[n]['pol_inclination'] > 0.6):\n",
    "                node_attr[n]['pol_inclination_grp'] = 2\n",
    "                \n",
    "        nx.set_node_attributes(temp_G, node_attr)\n",
    "        hom = nx.attribute_assortativity_coefficient(temp_G, \"pol_inclination_grp\")\n",
    "        net_homophily.append(hom)\n",
    "\n",
    "        for n in temp_G.nodes:\n",
    "            node_attr[n]['pol_inclination_grp'] = round(node_attr[n]['pol_inclination'] * 10)        \n",
    "        nx.set_node_attributes(temp_G, node_attr)\n",
    "        \n",
    "        hom = nx.attribute_assortativity_coefficient(temp_G, \"pol_inclination_grp\")\n",
    "        \n",
    "        if(math.isnan(hom) and len(set(nx.get_node_attributes(temp_G, \"pol_inclination_grp\").values())) == 1):\n",
    "            hom = 1\n",
    "        \n",
    "        polarization.append(pol)\n",
    "        network_homophily.append(hom)\n",
    "        polarity.append(avg_pol)\n",
    "        polarization2.append(compute_polarization(pol_inclination))\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            G = add_edges(G, data)\n",
    "            G = sever_edges(G, data)\n",
    "            \n",
    "            G = update_news_followers(G, data, SancGraphs)\n",
    "            SancGraphs = []\n",
    "            \n",
    "\n",
    "#         agent_states_df = pd.DataFrame(states)\n",
    "#         agent_pol_inclination_df = pd.DataFrame(agent_pol_inclination)\n",
    "#         activity_df = pd.DataFrame(users_activities)\n",
    "\n",
    "        # agent_states_df = pd.DataFrame()\n",
    "        # agent_pol_inclination_df = pd.DataFrame()\n",
    "        # activity_df = pd.DataFrame()\n",
    "        # privacy_df = pd.DataFrame()\n",
    "    \n",
    "    return updated_data, G_agents, sharing_details, polarization, polarization2, network_homophily, net_homophily, polarity, satisfaction, activity, privacy, states\n",
    "   \n",
    "\n",
    "def save_results_to_dir(run, epoch, data, mypath, sharing_details, net_polarization, net_polarization2, network_homophily, net_homophily, polarity, satisfaction, activity, privacy):\n",
    "    \n",
    "    results_df = pd.DataFrame(sharing_details, columns = ['topic', 'post_stance', 'author_id', 'num_of_agents_received', 'num_of_agents_not_received', \n",
    "                                                                  'num_of_spreader_agents', 'num_of_disinterested_agents'])\n",
    "    \n",
    "    results_df['network_polarization'] = net_polarization\n",
    "    results_df['net_polarization2'] = net_polarization2\n",
    "    results_df['network_homophily'] = network_homophily\n",
    "    results_df['network_homophily2'] = net_homophily\n",
    "    results_df['network_polarity'] = polarity\n",
    "    results_df['satisfaction'] = satisfaction\n",
    "    results_df['activity'] = activity\n",
    "    results_df['user_preference'] = privacy\n",
    "    \n",
    "    #mypath = '../results/sharing_details/'\n",
    "    results_df.to_csv(mypath + 'results_' + str(run) + '.csv')\n",
    "#     agent_states_df.to_csv(mypath + 'agent_states_' + str(run) + '.csv')\n",
    "#     agent_pol_inclination_df.to_csv(mypath + 'agent_polIncl_' + str(run) + '.csv')\n",
    "#     activity_df.to_csv(mypath + 'activity_' + str(run) + '.csv')\n",
    "    #data.to_csv(mypath + 'network_data_' + str(epoch) + '.csv')\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def save_graph(run, i, polarization, flag):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(range(len(polarization)), polarization)\n",
    "    if(flag == 3):\n",
    "        filepath = '../results/results_' + str(run) + '/satisfaction_' + str(i) +'.jpg'\n",
    "    elif(flag == 2):\n",
    "        filepath = '../results/results_' + str(run) + '/network_polarity_' + str(i) +'.jpg'\n",
    "    elif(flag == 1):\n",
    "        filepath = '../results/results_' + str(run) + '/polarization_' + str(i) +'.jpg'\n",
    "    elif(flag == 0):\n",
    "        filepath = '../results/results_' + str(run) + '/network_homophily_' + str(i) +'.jpg'\n",
    "        \n",
    "    plt.savefig(filepath)\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "    \n",
    "def save_data(run, i, data, flag, mypath):\n",
    "    \n",
    "    if os.path.isdir(mypath) == False:\n",
    "        os.mkdir(mypath)\n",
    "        \n",
    "    if(flag == 1):\n",
    "        data.to_csv(mypath + 'initial_data.csv')\n",
    "    elif(flag == 2):\n",
    "        data.to_csv(mypath + 'final_data_' + str(run) + str(i) +'.csv')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# post_conf = post_conf.groupby('topic', group_keys=False).apply(lambda x: x.sample(frac=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selective Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 Num of edges  1193\n",
      "1167 (3826, 3)\r"
     ]
    }
   ],
   "source": [
    "# sjt_flag= True\n",
    "topic_choices = [1,2,3,4,5,6]\n",
    "trending_topics = {1:[1, 1], 2:[1, 1], 3:[1, 1], 4:[1, 1], 5:[1, 1], 6:[1, 1]}\n",
    "news_stats = {100: [1, 1],\n",
    "              101: [1, 1],\n",
    "              102: [1, 1]}\n",
    "\n",
    "news_topic_pref = {100: [1,1,1,1,1,1],\n",
    "                      101: [2,2,2,1,1,1],\n",
    "                      102: [1,1,1,2,2,2]}\n",
    "\n",
    "user_sanc_sat, user_sanc_pr, user_sanc_act = {}, {}, {}\n",
    "\n",
    "lower_attd_th = 0.6\n",
    "upper_attd_th = 1.4\n",
    "se_flags = [False, True, True, True]\n",
    "se_thresholds = [0, 0.4, 1.0, 1.6]\n",
    "n_topics = 6\n",
    "topic_weights = [1] * (n_topics + 1)\n",
    "# post_conf =  pd.read_csv('data/posts_conf.csv')\n",
    "# seeds = [x for x in range(3,11)]\n",
    "seeds = [1,2,3,4,5,6,7,8,9,10]\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for k in seeds:\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "\n",
    "        topic_choices = [1,2,3,4,5,6]\n",
    "        trending_topics = {1:[1, 1], 2:[1, 1], 3:[1, 1], 4:[1, 1], 5:[1, 1], 6:[1, 1]}\n",
    "        news_stats = {100: [1, 1],\n",
    "                      101: [1, 1],\n",
    "                      102: [1, 1]}\n",
    "\n",
    "        news_topic_pref = {100: [1,1,1,1,1,1],\n",
    "                              101: [2,2,2,1,1,1],\n",
    "                              102: [1,1,1,2,2,2]}\n",
    "\n",
    "        user_sanc_sat, user_sanc_pr, user_sanc_act = {}, {}, {}\n",
    "        # k = 1\n",
    "        random.seed(k)\n",
    "        # data_path = 'initial_data_' + str(k) + '.csv'\n",
    "        data_path = 'initial_data_new.csv'\n",
    "        initial_data = pd.read_csv(data_path)\n",
    "\n",
    "        post_conf =  pd.read_csv('post_conf.csv')\n",
    "        post_conf = post_conf.rename(columns = {'issue': 'topic'})\n",
    "        post_conf['topic'] = post_conf.topic.replace(0, 6)\n",
    "        # post_conf = post_conf.groupby('topic', group_keys=False).apply(lambda x: x.sample(frac=0.01))\n",
    "\n",
    "        # initial_graph = Data.get_fb_network(initial_data)\n",
    "        # initial_data = initial_data[['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6', 'privacy', 'activity', 'satisfaction', 'lat_acc', 'lat_rej']]\n",
    "        # initial_data['pol_inclination'] = initial_data.iloc[:, :3].mean(axis=1) - initial_data.iloc[:, 3:6].mean(axis=1)\n",
    "        #     print(initial_data.pol_inclination.mean())\n",
    "        # initial_data_2 = pd.read_csv('../results/sharing_details_1/initial_data.csv')\n",
    "        # Data_obj = Data(k)\n",
    "        # initial_graph = Data_obj.get_fb_network(initial_data)\n",
    "\n",
    "        initial_graph = None\n",
    "        import pickle\n",
    "        with open('graph.pkl', 'rb') as f:\n",
    "            initial_graph = pickle.load(f)\n",
    "\n",
    "        # print(G)\n",
    "\n",
    "        # sys.exit()\n",
    "\n",
    "        G_share = None\n",
    "\n",
    "        # for i in range(4):\n",
    "\n",
    "        # if((k == 3) and (i == 0)):\n",
    "        #     continue\n",
    "        # i = 0\n",
    "\n",
    "        se_threshold = se_thresholds[i]\n",
    "        se_flag = se_flags[i]\n",
    "\n",
    "        data = initial_data.copy()\n",
    "        G = initial_graph.copy()\n",
    "\n",
    "        run = str(k) + str(i)\n",
    "        #print(i, end = \"\\t\")\n",
    "        #run = i\n",
    "\n",
    "        # print()\n",
    "\n",
    "        rep = abs(data[data['pol_inclination'] < 0]['pol_inclination'].sum())\n",
    "        dem = abs(data[data['pol_inclination'] > 0]['pol_inclination'].sum())\n",
    "        initial_pol = round((rep + dem)/data.shape[0], 6) \n",
    "        initial_homophily = nx.attribute_assortativity_coefficient(G, \"pol_inclination\")\n",
    "\n",
    "        if(math.isnan(initial_homophily) and len(set(nx.get_node_attributes(G, \"pol_inclination\").values())) == 1):\n",
    "            initial_homophily = [1]\n",
    "\n",
    "        mypath = 'results/SE/'\n",
    "        #         save_data(run, 0, initial_data, 1, mypath)\n",
    "        #     for i in range(2):\n",
    "\n",
    "        # G_share = start_simulation(i, k, data.copy(), G, post_conf, n_topics, lower_attd_th, upper_attd_th, k)\n",
    "        # sys.exit()\n",
    "\n",
    "        data, G, sharing_details, net_polarization, net_polarization2, network_homophily, net_homophily, polarity, satisfaction, activity, privacy, states = start_simulation(i, k, data, G, post_conf, n_topics, lower_attd_th, upper_attd_th, k, trending_topics, topic_choices, news_topic_pref)\n",
    "        # net_polarization = initial_pol + net_polarization\n",
    "        # network_homophily = initial_homophily + network_homophily\n",
    "\n",
    "        # print(data.shape)\n",
    "\n",
    "        save_results_to_dir(run, i, data.copy(), mypath, sharing_details, net_polarization, net_polarization2, network_homophily, net_homophily, polarity, satisfaction, activity, privacy)\n",
    "        #         save_graph(run, i, net_polarization, 1)\n",
    "        #         save_graph(run, i, network_homophily, 0)\n",
    "        #         save_graph(run, i, polarity, 2)\n",
    "        #         save_graph(run, i, satisfaction, 3)\n",
    "        save_data(run, i, data.copy(), 2, mypath)\n",
    "        \n",
    "        print(k, i, 'Num of edges ', len(list(G.edges()))) \n",
    "#         import pickle\n",
    "\n",
    "#         # Save graph using pickle\n",
    "#         with open(f'{mypath}graph_{run}.pkl', 'wb') as f:\n",
    "#             pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # color_map = ['red'] * 50 + ['blue'] * 50 + ['orange', 'green', 'brown']  # Regular, Influential, Superinfluential\n",
    "\n",
    "# indegrees = [G.degree(n) * 10 for n in G.nodes()]  # Scale for visibility\n",
    "\n",
    "# pos = nx.spring_layout(G)\n",
    "# # sns.set_style(\"white\")\n",
    "# # nx.draw(G, pos, with_labels=True)\n",
    "# # plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# nx.draw(G, with_labels=False, edge_color=\"gray\", node_size=indegrees)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sorted_nodes = sorted(G.nodes, key=lambda n: G.degree(n), reverse=True)\n",
    "# sorted_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_10",
   "language": "python",
   "name": "py3_10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
