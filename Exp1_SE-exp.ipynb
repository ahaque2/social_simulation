{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import time, enum, math\n",
    "import pylab as plt\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from state import State\n",
    "from Agent import MyAgent\n",
    "from NetworkInformationDiffusionModel import NetworkInformationDiffusionModel\n",
    "# from Visualization import Visualization\n",
    "from Data import Data\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_share_prob(potential_users):\n",
    "    \n",
    "    user_id = None\n",
    "    \n",
    "    sharing_prob = potential_users['user_activity'] * potential_users['privacy_preference']\n",
    "    \n",
    "    # 50% of the times make a random selection of author\n",
    "    # if(random.random() > 0.50  or user_id == None):\n",
    "    rnd = random.random()\n",
    "    \n",
    "    if(rnd > 0.50):\n",
    "        user_id = int(potential_users.sample(1)['id'].values[0])\n",
    "        \n",
    "    elif(len(sharing_prob) > 0):\n",
    "        user_id = int(sharing_prob.idxmax())\n",
    "        \n",
    "    return user_id\n",
    "   \n",
    "def pick_an_author(data, post):\n",
    "    \n",
    "    issue_id = post[0]\n",
    "    post_stance = post[1]\n",
    "    issue_mentioned = 'topic_' + str(int(issue_id))\n",
    "    user_id = None\n",
    "    \n",
    "    if data[data[issue_mentioned] <= 0].shape[0] == 0 or data[data[issue_mentioned] >= 0].shape[0] == 0:\n",
    "        return None\n",
    "    \n",
    "    agent_inclination = data[issue_mentioned]\n",
    "    if(post_stance >= 0):\n",
    "        potential_users = data[data[issue_mentioned] >= 0]\n",
    "        selected_author = compute_share_prob(potential_users)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        potential_users = data[data[issue_mentioned] < 0]\n",
    "        selected_author = compute_share_prob(potential_users)\n",
    "    \n",
    "    return selected_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_data(df, data, attr):\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if(df.iloc[i][attr] != data.iloc[i][attr]):\n",
    "            print(\"old value \", df.iloc[i][attr], \" \\t New value\", data.iloc[i][attr])\n",
    "\n",
    "def update_privacy_preference(data, G, user, agg_sanct):\n",
    "    \n",
    "    old_privacy_preference = data.copy().iloc[user]['privacy_preference']\n",
    "    \n",
    "    ## NEED TO CHANGE THIS FORMULA TO BE SOMETHING MORE MEANINGFUL\n",
    "    new_privacy_preference = old_privacy_preference + (agg_sanct * 0.1)\n",
    "    \n",
    "    #Update the user activity with the new value (a bounded value between 0 and 1)\n",
    "    new_privacy_preference = max(min(1, new_privacy_preference), 0)\n",
    "    #data.at[user, 'privacy_preference'] = new_privacy_preference\n",
    "    \n",
    "    if(old_privacy_preference == new_privacy_preference and agg_sanct > 1e-14 and old_privacy_preference != 1):\n",
    "        print(old_privacy_preference)\n",
    "        print(agg_sanct)\n",
    "        sys.exit()\n",
    "    \n",
    "    data['privacy_preference'].iloc[user] = new_privacy_preference\n",
    "    G.nodes[user]['privacy_preference'] = new_privacy_preference\n",
    "    \n",
    "    return data, G\n",
    "    \n",
    "def attitude_shift(sanction_score, att_diff, author_inclination, reciever_inclination):\n",
    "    \n",
    "    attitude_shft = 0.1 * sanction_score * 1/(att_diff+1)\n",
    "    if(author_inclination >= reciever_inclination):\n",
    "        new_user_incl = author_inclination - attitude_shft\n",
    "    else:\n",
    "        new_user_incl = author_inclination + attitude_shft\n",
    "        \n",
    "    return new_user_incl\n",
    "\n",
    "\n",
    "def update_user_satisfaction(data, G, user, agg_sanct):\n",
    "    \n",
    "    user_data = data.iloc[user]\n",
    "    \n",
    "    old_user_satisfaction = user_data['user_satisfaction']\n",
    "    \n",
    "    ## NEED TO CHANGE THIS FORMULA TO BE SOMETHING MORE MEANINGFUL\n",
    "    new_user_satisfaction = old_user_satisfaction + (agg_sanct * 0.1)\n",
    "    \n",
    "    data['user_satisfaction'].iloc[user] = new_user_satisfaction\n",
    "    G.nodes[user]['user_satisfaction'] = new_user_satisfaction\n",
    "    \n",
    "    return data, G\n",
    "\n",
    "def clamp(num, minn, maxx):\n",
    "    return minn if num < minn else maxx if num > maxx else num\n",
    "\n",
    "\n",
    "def update_user_activity(data, G, state, post, lower_attd_th, upper_attd_th):\n",
    "    \n",
    "    old_user_activity = data.copy()\n",
    "    # old_user_activity['shift'] = [0] * old_user_activity.shape[0]\n",
    "    issue_id = post['topic']\n",
    "    \n",
    "    # user_stance = data[f'issue_{issue_id}'].copy()\n",
    "    # old_user_activity[(abs(user_stance - post['stance']) < lower_attd_th)]\n",
    "    # print(old_user_activity[f'issue_{issue_id}'].shape)\n",
    "    \n",
    "    old_user_activity['shift'] = np.select([abs(old_user_activity[f'topic_{issue_id}'] - post['stance']) < lower_attd_th, abs(old_user_activity[f'topic_{issue_id}'] - post['stance']) > upper_attd_th], [1, -1], default=0)\n",
    "    \n",
    "    # print(old_user_activity['shift'].value_counts())\n",
    "    \n",
    "    state_df = pd.Series(state)\n",
    "    state_df = state_df.map(lambda x: 1 if x != 2 else 0)\n",
    "    \n",
    "    # print(state_df.value_counts())\n",
    "    \n",
    "    old_user_activity['user_activity'] = old_user_activity['user_activity'] + old_user_activity['user_activity'] * old_user_activity['shift'] * state_df * post['stance'] * 0.1\n",
    "    old_user_activity['user_activity'] = old_user_activity['user_activity'].clip(lower=0, upper=1)\n",
    "    # print(new_user_activity.describe())\n",
    "    # sys.exit()\n",
    "\n",
    "    return old_user_activity\n",
    "\n",
    "def update_user_preferences(sG, G, data, state, post, lower_attd_th, upper_attd_th):\n",
    "    \n",
    "    issue_id = post['topic']\n",
    "    labels = nx.get_edge_attributes(sG,'weight')\n",
    "    outgoing = list(set([x[0] for x in labels.keys()]))\n",
    "    incoming = list(set([x[1] for x in labels.keys()]))\n",
    "    updated_data = data.copy()\n",
    "    \n",
    "    # print(updated_data.shape)\n",
    "    # print(updated_data)\n",
    "    # sys.exit()\n",
    "    \n",
    "    for n in incoming:\n",
    "        lab = [labels[x] for x in labels if x[1] == n]\n",
    "        agg_sanct = sum(lab)/len(lab)\n",
    "        \n",
    "        # print(agg_sanct)\n",
    "        \n",
    "        updated_data, G = update_privacy_preference(data.copy(), G, n, agg_sanct)\n",
    "        updated_data, G = update_user_satisfaction(updated_data, G, n, agg_sanct)\n",
    "    \n",
    "    updated_data = update_user_activity(updated_data, G, state, post, lower_attd_th, upper_attd_th)\n",
    "        \n",
    "    for node in incoming:\n",
    "        \n",
    "        edges = sG.in_edges(node, data=True)\n",
    "        gama = 0\n",
    "        temp_df = pd.DataFrame(columns = ['author', 'reciever', 'att_diff', 'sanction_scores'])\n",
    "        \n",
    "        for x in edges:\n",
    "            reciever = x[0]\n",
    "            author = x[1]\n",
    "            sanction_score = x[2]['weight']\n",
    "\n",
    "            reciever_inclination = updated_data[updated_data['id'] == reciever]['topic_' + str(issue_id)].values[0]\n",
    "            author_inclination = updated_data[updated_data['id'] == author]['topic_' + str(issue_id)].values[0]\n",
    "            att_diff =  abs(reciever_inclination - author_inclination)\n",
    "            \n",
    "            temp_dict = {'author':author_inclination, 'reciever':reciever_inclination, 'att_diff':att_diff, 'sanction_scores':sanction_score}\n",
    "            temp_df = temp_df.append(temp_dict, ignore_index=True)\n",
    "            \n",
    "        temp_df['adj_att_diff'] = temp_df['att_diff'] + 1\n",
    "        \n",
    "        temp_df['att_shift'] = temp_df['sanction_scores'] * 0.1/temp_df['adj_att_diff']\n",
    "        \n",
    "        postive_shift = temp_df[temp_df['att_diff'] < lower_attd_th]\n",
    "        negative_shift = temp_df[temp_df['att_diff'] > upper_attd_th]\n",
    "        \n",
    "        if(postive_shift.shape[0] > 0 and negative_shift.shape[0] > 0):\n",
    "            att_shift = postive_shift['att_shift'].mean() - negative_shift['att_shift'].mean()\n",
    "        elif(postive_shift.shape[0] == 0 and negative_shift.shape[0] > 0):\n",
    "            att_shift = (-1) * negative_shift['att_shift'].mean()\n",
    "        elif(negative_shift.shape[0] == 0 and postive_shift.shape[0] > 0):\n",
    "            att_shift = postive_shift['att_shift'].mean()\n",
    "        else:\n",
    "            att_shift = 0\n",
    "            \n",
    "        att_shift = clamp(att_shift, -0.20, 0.20)\n",
    "\n",
    "        new_user_incl = author_inclination + att_shift\n",
    "        new_user_incl = clamp(new_user_incl, -1, 1)\n",
    "        \n",
    "        if(math.isnan(new_user_incl)):\n",
    "            print(\"here\")\n",
    "            print(\"author_inclination \", author_inclination)\n",
    "            print(\"att_shift \", att_shift)\n",
    "            print(\"new_user_incl \", new_user_incl)\n",
    "            print(\"postive_shift \\n\", postive_shift)\n",
    "            print(\"negative_shift \\n\", negative_shift)\n",
    "            print(\"DF \\n\", temp_df)\n",
    "            sys.exit(0)\n",
    "        \n",
    "        updated_data['topic_' + str(issue_id)].iloc[author] = new_user_incl\n",
    "        G.nodes[author]['topic_' + str(issue_id)] = new_user_incl\n",
    "    \n",
    "    return updated_data, G\n",
    "\n",
    "def update_pol_pol_in_graph(data, G):\n",
    "    \n",
    "    for n in G:\n",
    "        G.nodes[n]['pol_inclination'] = data.iloc[n]['pol_inclination']\n",
    "        \n",
    "    return G\n",
    "\n",
    "def run_simulation(post, G, steps, seed):\n",
    "\n",
    "    model = NetworkInformationDiffusionModel(post, G, se_flag, se_threshold, issue_weights, seed)\n",
    "    for i in range(steps):\n",
    "\n",
    "        model.reset_randomizer(seed)\n",
    "        model.step(i)\n",
    "        #agent_state = model.datacollector.get_agent_vars_dataframe()\n",
    "        #X = pd.pivot_table(agent_state.reset_index(), index='Step', columns='State', aggfunc=np.size, fill_value=0)  \n",
    "        \n",
    "    #print(model.datacollector.get_agent_vars_dataframe())\n",
    "    agent_state = model.datacollector.get_agent_vars_dataframe()\n",
    "    \n",
    "    states = [int(i.state) for i in model.grid.get_all_cell_contents()]\n",
    "    agents = model.agents\n",
    "    \n",
    "    return model, states, agents, model.G, model.G_share, agent_state\n",
    "\n",
    "def start_simulation(c_i, c_k, data, G, post_conf, n_issues, lower_attd_th, upper_attd_th, seed, Data_obj):\n",
    "    \n",
    "    steps=50\n",
    "    SimModel, states, agents, AgentGraphs, SancGraphs, AgentStates, runtime = {}, [], [], [], [], [], []\n",
    "    network_homophily = []\n",
    "    net_homophily = []\n",
    "    polarization, polarization2 = [], []\n",
    "    user_satisfaction = []\n",
    "    user_activity = []\n",
    "    users_activities = []\n",
    "    privacy_preference = []\n",
    "    polarity = []\n",
    "    avg_polarity = []\n",
    "    agent_pol_inclination = []\n",
    "    i = 0\n",
    "    sharing_details = []\n",
    "    updated_data = None\n",
    "    print(c_k, \"\\t\", c_i, \"\\t\")   \n",
    "    \n",
    "    for j, post in post_conf.iterrows():\n",
    "\n",
    "        i+=1\n",
    "        print(i, end=\"\\r\")\n",
    "        \n",
    "        pc = (post['topic'], post['stance'])\n",
    "        #print(\"post \", pc)\n",
    "\n",
    "        st=time.time()\n",
    "        author_id = pick_an_author(data, pc)\n",
    "        #author_id = int(post['author_id'])\n",
    "        \n",
    "        if(author_id == None):\n",
    "            continue\n",
    "\n",
    "        post = dict()\n",
    "        post['author'] = author_id\n",
    "        post['topic'] = int(pc[0])\n",
    "        post['stance'] = pc[1]\n",
    "\n",
    "        SimModel[j], state, agent, G_agents, G_sanctions, agent_state = run_simulation(post, G, steps, seed)\n",
    "        \n",
    "        # print(len(state))\n",
    "        # print(agent_state)\n",
    "        # sys.exit(0)\n",
    "        \n",
    "        et = time.time()\n",
    "        rt = round(et-st, 6)\n",
    "\n",
    "        states.append(state) \n",
    "        agents.append(agent)\n",
    "        AgentGraphs.append(G_agents)\n",
    "        SancGraphs.append(G_sanctions)\n",
    "        AgentStates.append(agent_state)\n",
    "        runtime.append(rt)\n",
    "\n",
    "        author = author_id\n",
    "        #received_agents_count = sum([1 for x in state if x == 1])\n",
    "        not_received_agents_count = sum([1 for x in state if x == 2])\n",
    "        spreader_agents_count = sum([1 for x in state if x == 3])\n",
    "        disinterested_agents_counts = sum([1 for x in state if x == 4])\n",
    "        received_agents_count = spreader_agents_count + disinterested_agents_counts\n",
    "\n",
    "        #print(state)\n",
    "        sharing_details.append([pc[0], round(pc[1], 6), author_id, received_agents_count, not_received_agents_count, spreader_agents_count, disinterested_agents_counts])\n",
    "        #print(sharing_details)\n",
    "\n",
    "        # Visualization().plot_sim_network(G_agents, state)\n",
    "        # Visualization().plot_sanction_graph(G_sanctions)\n",
    "        # sys.exit()\n",
    "        \n",
    "        # Update user preferences based on sanctions received from other agents\n",
    "        data_updated, G_agents = update_user_preferences(G_sanctions, G_agents, data.copy(), state, post, lower_attd_th, upper_attd_th)\n",
    "        \n",
    "        updated_data = data_updated.copy()\n",
    "        \n",
    "        # print(\"Comparison \", data['user_activity'].compare(updated_data['user_activity']))\n",
    "        data = data_updated\n",
    "        \n",
    "#         print(updated_data.shape, updated_data.columns)\n",
    "#         print(n_issues)\n",
    "        \n",
    "#         issues = ['issue_' + str(x) for x in range(n_issues)]\n",
    "        \n",
    "#         kx = updated_data[issues].mean(axis = 1)\n",
    "#         temp_df = updated_data[issues]\n",
    "#         print(temp_df.shape, temp_df.columns)\n",
    "#         print(temp_df.head())\n",
    "#         print(kx)\n",
    "        \n",
    "#         sys.exit()\n",
    "        \n",
    "        pol_inclination = Data_obj.get_agent_pol_inclinations(updated_data, n_issues)\n",
    "        \n",
    "        if(updated_data['pol_inclination'].isna().sum() > 0):\n",
    "            #print(pol_inclination)\n",
    "            \n",
    "            print(\"updated_data \", updated_data)\n",
    "            sys.exit()\n",
    "            \n",
    "        updated_data['pol_inclination'] = pol_inclination\n",
    "        \n",
    "        agent_pol_inclination.append(pol_inclination)\n",
    "        \n",
    "        G_agents = update_pol_pol_in_graph(updated_data, G_agents)\n",
    "        \n",
    "        net_user_satisfaction = updated_data['user_satisfaction'].mean()\n",
    "        user_satisfaction.append(net_user_satisfaction)\n",
    "        \n",
    "        mean_user_activity = updated_data['user_activity'].mean()\n",
    "        users_activities.append(updated_data['user_activity'])\n",
    "        user_activity.append(mean_user_activity)\n",
    "        \n",
    "        mean_privacy_preference = updated_data['privacy_preference'].mean()\n",
    "        users_activities.append(updated_data['privacy_preference'])\n",
    "        privacy_preference.append(mean_privacy_preference)\n",
    "        \n",
    "        pol = round(math.sqrt(sum([x*x for x in updated_data['pol_inclination']])/updated_data.shape[0]), 6)\n",
    "        \n",
    "        if(math.isnan(pol)):\n",
    "            \n",
    "            print(updated_data['pol_inclination'])\n",
    "            sys.exit()\n",
    "        \n",
    "        avg_pol = round(updated_data['pol_inclination'].mean(), 6)\n",
    "        \n",
    "        temp_G = G.copy()\n",
    "        \n",
    "        node_attr = updated_data.set_index('id').to_dict('index')\n",
    "        # print(node_attr)\n",
    "        # print((data['user_activity'] - updated_data['user_activity']).sum())\n",
    "        \n",
    "        # sys.exit()\n",
    "        nx.set_node_attributes(temp_G, node_attr)\n",
    "         \n",
    "        for n in temp_G.nodes:\n",
    "            if(node_attr[n]['pol_inclination'] < -0.6):\n",
    "                node_attr[n]['pol_inclination_grp'] = -2\n",
    "            elif((node_attr[n]['pol_inclination'] >= -0.6) and ((node_attr[n]['pol_inclination'] < -0.2))):\n",
    "                node_attr[n]['pol_inclination_grp'] = -1\n",
    "            elif((node_attr[n]['pol_inclination'] >= -0.2) and ((node_attr[n]['pol_inclination'] <= 0.2))):\n",
    "                node_attr[n]['pol_inclination_grp'] = 0\n",
    "            elif((node_attr[n]['pol_inclination'] > 0.2) and ((node_attr[n]['pol_inclination'] <= 0.6))):\n",
    "                node_attr[n]['pol_inclination_grp'] = 1\n",
    "            elif(node_attr[n]['pol_inclination'] > 0.6):\n",
    "                node_attr[n]['pol_inclination_grp'] = 2\n",
    "                \n",
    "        nx.set_node_attributes(temp_G, node_attr)\n",
    "        hom = nx.attribute_assortativity_coefficient(temp_G, \"pol_inclination_grp\")\n",
    "        net_homophily.append(hom)\n",
    "\n",
    "        for n in temp_G.nodes:\n",
    "            node_attr[n]['pol_inclination_grp'] = round(node_attr[n]['pol_inclination'] * 10)        \n",
    "        nx.set_node_attributes(temp_G, node_attr)\n",
    "        \n",
    "        hom = nx.attribute_assortativity_coefficient(temp_G, \"pol_inclination_grp\")\n",
    "        \n",
    "        if(math.isnan(hom) and len(set(nx.get_node_attributes(temp_G, \"pol_inclination_grp\").values())) == 1):\n",
    "            hom = 1\n",
    "        \n",
    "        polarization.append(pol)\n",
    "        network_homophily.append(hom)\n",
    "        polarity.append(avg_pol)\n",
    "        polarization2.append(Data_obj.compute_polarization(pol_inclination))\n",
    "\n",
    "#         agent_states_df = pd.DataFrame(states)\n",
    "#         agent_pol_inclination_df = pd.DataFrame(agent_pol_inclination)\n",
    "#         user_activity_df = pd.DataFrame(users_activities)\n",
    "\n",
    "        agent_states_df = pd.DataFrame()\n",
    "        agent_pol_inclination_df = pd.DataFrame()\n",
    "        user_activity_df = pd.DataFrame()\n",
    "        privacy_preference_df = pd.DataFrame()\n",
    "    \n",
    "    return updated_data, G_agents, sharing_details, polarization, polarization2, network_homophily, net_homophily, polarity, user_satisfaction, user_activity, privacy_preference, agent_states_df, agent_pol_inclination_df, user_activity_df, privacy_preference_df\n",
    "   \n",
    "\n",
    "def save_results_to_dir(run, epoch, data, mypath, sharing_details, net_polarization, net_polarization2, network_homophily, net_homophily, polarity, user_satisfaction, user_activity, privacy_preference, agent_states_df, agent_pol_inclination_df, user_activity_df):\n",
    "    \n",
    "    results_df = pd.DataFrame(sharing_details, columns = ['party_mentioned', 'post_stance', 'author_id', 'num_of_agents_received', 'num_of_agents_not_received', \n",
    "                                                                  'num_of_spreader_agents', 'num_of_disinterested_agents'])\n",
    "    \n",
    "    results_df['network_polarization'] = net_polarization\n",
    "    results_df['net_polarization2'] = net_polarization2\n",
    "    results_df['network_homophily'] = network_homophily\n",
    "    results_df['network_homophily2'] = net_homophily\n",
    "    results_df['network_polarity'] = polarity\n",
    "    results_df['user_satisfaction'] = user_satisfaction\n",
    "    results_df['user_activity'] = user_activity\n",
    "    results_df['user_preference'] = privacy_preference\n",
    "    \n",
    "    #mypath = '../results/sharing_details/'\n",
    "    results_df.to_csv(mypath + 'results_' + str(run) + '.csv')\n",
    "#     agent_states_df.to_csv(mypath + 'agent_states_' + str(run) + '.csv')\n",
    "#     agent_pol_inclination_df.to_csv(mypath + 'agent_polIncl_' + str(run) + '.csv')\n",
    "#     user_activity_df.to_csv(mypath + 'user_activity_' + str(run) + '.csv')\n",
    "    #data.to_csv(mypath + 'network_data_' + str(epoch) + '.csv')\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def save_graph(run, i, polarization, flag):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(range(len(polarization)), polarization)\n",
    "    if(flag == 3):\n",
    "        filepath = '../results/results_' + str(run) + '/user_satisfaction_' + str(i) +'.jpg'\n",
    "    elif(flag == 2):\n",
    "        filepath = '../results/results_' + str(run) + '/network_polarity_' + str(i) +'.jpg'\n",
    "    elif(flag == 1):\n",
    "        filepath = '../results/results_' + str(run) + '/polarization_' + str(i) +'.jpg'\n",
    "    elif(flag == 0):\n",
    "        filepath = '../results/results_' + str(run) + '/network_homophily_' + str(i) +'.jpg'\n",
    "        \n",
    "    plt.savefig(filepath)\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "    \n",
    "def save_data(run, i, data, flag, mypath):\n",
    "    \n",
    "    if os.path.isdir(mypath) == False:\n",
    "        os.mkdir(mypath)\n",
    "        \n",
    "    if(flag == 1):\n",
    "        data.to_csv(mypath + 'initial_data.csv')\n",
    "    elif(flag == 2):\n",
    "        data.to_csv(mypath + 'final_data_' + str(run) + str(i) +'.csv')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial_data = pd.read_csv('data/initial_data_3.csv')\n",
    "# initial_data_2 = pd.read_csv('../results/sharing_details_1/initial_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial_data.pol_inclination.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_distribution(series):\n",
    "    sns.histplot(series, kde=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_issues= 6\n",
    "post_conf =  pd.read_csv('post_conf.csv')\n",
    "post_conf = post_conf.rename(columns = {'issue': 'topic'})\n",
    "# initial_graph = Data.get_fb_network(initial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_distribution(post_conf[post_conf.issue == 1].stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# post_conf = post_conf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# post_conf = post_conf.sample(frac = 0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selective Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 0 \t\n",
      "1\r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'topic_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/venv/py3_10/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/py3_10/lib/python3.10/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/venv/py3_10/lib/python3.10/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topic_2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2778815/3970753193.py\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#     for i in range(2):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_polarization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_polarization2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_homophily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_homophily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_satisfaction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_activity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivacy_preference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_states_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_pol_inclination_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_activity_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivacy_preference_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_issues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_attd_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_attd_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;31m# net_polarization = initial_pol + net_polarization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# network_homophily = initial_homophily + network_homophily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2778815/2716406054.py\u001b[0m in \u001b[0;36mstart_simulation\u001b[0;34m(c_i, c_k, data, G, post_conf, n_issues, lower_attd_th, upper_attd_th, seed, Data_obj)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mauthor_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_an_author\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;31m#author_id = int(post['author_id'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2778815/1021768508.py\u001b[0m in \u001b[0;36mpick_an_author\u001b[0;34m(data, post)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0missue_mentioned\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0missue_mentioned\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/py3_10/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/py3_10/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topic_2'"
     ]
    }
   ],
   "source": [
    "# sjt_flag= True\n",
    "lower_attd_th = 0.6\n",
    "upper_attd_th = 1.4\n",
    "se_flags = [False, True, True, True]\n",
    "se_thresholds = [0, 0.4, 1.0, 1.6]\n",
    "n_issues = 6\n",
    "issue_weights = [1] * n_issues\n",
    "# post_conf =  pd.read_csv('data/posts_conf.csv')\n",
    "# seeds = [x for x in range(3,11)]\n",
    "seeds = [1,2,3,4,5] #,6,7,8,9,10]\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for k in seeds:\n",
    "    \n",
    "    random.seed(k)\n",
    "    data_path = 'initial_data_1.csv'\n",
    "    initial_data = pd.read_csv(data_path)\n",
    "#     print(initial_data.pol_inclination.mean())\n",
    "    # initial_data_2 = pd.read_csv('../results/sharing_details_1/initial_data.csv')\n",
    "    Data_obj = Data(k)\n",
    "    initial_graph = Data_obj.get_fb_network(initial_data)\n",
    "\n",
    "    for i in range(4):\n",
    "        \n",
    "        if((k == 3) and (i == 0)):\n",
    "            continue\n",
    "\n",
    "        se_threshold = se_thresholds[i]\n",
    "        se_flag = se_flags[i]\n",
    "\n",
    "        data = initial_data.copy()\n",
    "        G = initial_graph.copy()\n",
    "\n",
    "        run = str(k) + str(i)\n",
    "        #print(i, end = \"\\t\")\n",
    "        #run = i\n",
    "\n",
    "        rep = abs(data[data['pol_inclination'] < 0]['pol_inclination'].sum())\n",
    "        dem = abs(data[data['pol_inclination'] > 0]['pol_inclination'].sum())\n",
    "        initial_pol = round((rep + dem)/data.shape[0], 6) \n",
    "        initial_homophily = nx.attribute_assortativity_coefficient(G, \"pol_inclination\")\n",
    "        \n",
    "        if(math.isnan(initial_homophily) and len(set(nx.get_node_attributes(G, \"pol_inclination\").values())) == 1):\n",
    "            initial_homophily = [1]\n",
    "        \n",
    "        mypath = 'results/new_results_new/SE/'\n",
    "#         save_data(run, 0, initial_data, 1, mypath)\n",
    "    #     for i in range(2):\n",
    "\n",
    "        data, G, sharing_details, net_polarization, net_polarization2, network_homophily, net_homophily, polarity, user_satisfaction, user_activity, privacy_preference, agent_states_df, agent_pol_inclination_df, user_activity_df, privacy_preference_df = start_simulation(i, k, data.copy(), G, post_conf, n_issues, lower_attd_th, upper_attd_th, k, Data_obj)\n",
    "        # net_polarization = initial_pol + net_polarization\n",
    "        # network_homophily = initial_homophily + network_homophily\n",
    "        save_results_to_dir(run, i, data.copy(), mypath, sharing_details, net_polarization, net_polarization2, network_homophily, net_homophily, polarity, user_satisfaction, user_activity, privacy_preference, agent_states_df, agent_pol_inclination_df, user_activity_df)\n",
    "#         save_graph(run, i, net_polarization, 1)\n",
    "#         save_graph(run, i, network_homophily, 0)\n",
    "#         save_graph(run, i, polarity, 2)\n",
    "#         save_graph(run, i, user_satisfaction, 3)\n",
    "        save_data(run, i, data.copy(), 2, mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import mesa\n",
    "# from mesa.time import RandomActivation\n",
    "# class MyAgent(mesa.Agent):\n",
    "#     def __init__(self, name, model):\n",
    "#         super().__init__(name, model)\n",
    "#         self.name = name\n",
    "        \n",
    "#     def step(self):\n",
    "#         print(\"{} activated\".format(self.name))\n",
    "    \n",
    "#         # Whatever else the agent does when activated\n",
    "    \n",
    "# class MyModel(mesa.Model):\n",
    "#     def __init__(self, n_agents):\n",
    "#         super().__init__()\n",
    "#         self.schedule = mesa.time.RandomActivation(self)\n",
    "#         self.grid = mesa.space.MultiGrid(10, 10, torus=True)\n",
    "#         for i in range(n_agents):\n",
    "#             a = MyAgent(i, self)\n",
    "#             self.schedule.add(a)\n",
    "#             coords = (self.random.randrange(0, 10), self.random.randrange(0, 10))\n",
    "#             self.grid.place_agent(a, coords)\n",
    "\n",
    "#     def step(self):\n",
    "#         self.schedule.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_10",
   "language": "python",
   "name": "py3_10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
